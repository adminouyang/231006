#!/usr/bin/env python3
import os
import asyncio
import configparser
from pathlib import Path
from typing import List, Set
import re
import logging
from core import (
    SourceFetcher,
    PlaylistParser,
    AutoCategoryMatcher,
    SpeedTester,
    ResultExporter
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class StageProgress:
    """é˜¶æ®µè¿›åº¦æ˜¾ç¤ºå™¨"""
    
    def __init__(self, stage_name: str, total: int, update_interval: int = 10):
        self.stage = stage_name
        self.total = max(total, 1)
        self.current = 0
        self.bar_length = 30
        self.update_interval = update_interval

    def update(self, n=1):
        self.current = min(self.current + n, self.total)
        if self.current % self.update_interval == 0 or self.current == self.total:
            percent = self.current / self.total * 100
            filled = int(self.bar_length * self.current / self.total)
            bar = 'â–Š' * filled + ' ' * (self.bar_length - filled)
            print(f"\r{self.stage} [{bar}] {percent:.1f}%", end='', flush=True)

    def complete(self):
        bar = 'â–Š' * self.bar_length
        print(f"\r{self.stage} [{bar}] 100.0%")


def is_blacklisted(channel, blacklist):
    """æ£€æŸ¥é¢‘é“æ˜¯å¦åœ¨é»‘åå•ä¸­"""
    for entry in blacklist:
        if entry in channel.url or channel.url == entry or channel.name == entry:
            return True
    return False


def write_failed_urls(failed_urls: Set[str], config):
    """å°†å¤±è´¥çš„ URL å†™å…¥æ–‡ä»¶"""
    try:
        # ä»é…ç½®æ–‡ä»¶ä¸­è·å–å¤±è´¥ URL çš„è·¯å¾„
        failed_urls_path = Path(config.get('PATHS', 'failed_urls_path', fallback='config/failed_urls.txt'))
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        failed_urls_path.parent.mkdir(parents=True, exist_ok=True)

        # å†™å…¥å¤±è´¥çš„ URL
        with open(failed_urls_path, 'w', encoding='utf-8') as f:
            for url in failed_urls:
                f.write(f"{url}\n")
        logger.info(f"ğŸ“ å¤±è´¥çš„ URL å·²å†™å…¥: {failed_urls_path}")
    except Exception as e:
        logger.error(f"âŒ å†™å…¥å¤±è´¥ URL æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")


def classify_and_write_ips(channels: List['Channel'], config, output_dir: Path, matcher):
    """
    åˆ†ç±» IPv4 å’Œ IPv6 åœ°å€ï¼Œå¹¶å°†ç»“æœå†™å…¥æ–‡ä»¶ã€‚
    æ–‡ä»¶æ ¼å¼ï¼š
    åˆ†ç±»åç§°,#genre#
    é¢‘é“åç§°,URL
    """
    # é¦–å…ˆå¯¹é¢‘é“æŒ‰ç…§æ¨¡æ¿é¡ºåºè¿›è¡Œæ’åº
    sorted_channels = matcher.sort_channels_by_template(channels)

    ipv4_channels = []
    ipv6_channels = []

    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… IPv4 å’Œ IPv6 åœ°å€
    ipv4_pattern = re.compile(r'http://\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}')
    ipv6_pattern = re.compile(r'http://\[[a-fA-F0-9:]+]')

    # ç»Ÿè®¡æ¯ä¸ªåˆ†ç±»çš„é¢‘é“æ•°é‡
    category_counts = {}
    for channel in sorted_channels:
        if ipv4_pattern.search(channel.url):
            ipv4_channels.append(channel)
            category_counts[channel.category] = category_counts.get(channel.category, 0) + 1
        elif ipv6_pattern.search(channel.url):
            ipv6_channels.append(channel)
            category_counts[channel.category] = category_counts.get(channel.category, 0) + 1

    # å†™å…¥ IPv4 åœ°å€
    ipv4_output_path = Path(config.get('PATHS', 'ipv4_output_path', fallback='ipv4.txt'))
    with open(output_dir / ipv4_output_path, 'w', encoding='utf-8') as f:
        current_category = None
        for channel in ipv4_channels:
            # å¦‚æœåˆ†ç±»å‘ç”Ÿå˜åŒ–ï¼Œå†™å…¥åˆ†ç±»è¡Œ
            if channel.category != current_category:
                if current_category is not None:
                    f.write("\n")  # åœ¨åˆ†ç±»ä¹‹é—´æ·»åŠ ç©ºè¡Œ
                f.write(f"{channel.category},#genre#\n")
                current_category = channel.category
            # å†™å…¥é¢‘é“ä¿¡æ¯
            f.write(f"{channel.name},{channel.url}\n")
    logger.info(f"ğŸ“ IPv4 åœ°å€å·²å†™å…¥: {output_dir / ipv4_output_path}")

    # å†™å…¥ IPv6 åœ°å€
    ipv6_output_path = Path(config.get('PATHS', 'ipv6_output_path', fallback='ipv6.txt'))
    with open(output_dir / ipv6_output_path, 'w', encoding='utf-8') as f:
        current_category = None
        for channel in ipv6_channels:
            # å¦‚æœåˆ†ç±»å‘ç”Ÿå˜åŒ–ï¼Œå†™å…¥åˆ†ç±»è¡Œ
            if channel.category != current_category:
                if current_category is not None:
                    f.write("\n")  # åœ¨åˆ†ç±»ä¹‹é—´æ·»åŠ ç©ºè¡Œ
                f.write(f"{channel.category},#genre#\n")
                current_category = channel.category
            # å†™å…¥é¢‘é“ä¿¡æ¯
            f.write(f"{channel.name},{channel.url}\n")
    logger.info(f"ğŸ“ IPv6 åœ°å€å·²å†™å…¥: {output_dir / ipv6_output_path}")


async def main():
    """ä¸»å·¥ä½œæµç¨‹"""
    try:
        # åˆå§‹åŒ–é…ç½®
        config = configparser.ConfigParser()
        config_path = Path('config/config.ini')
        if not config_path.exists():
            raise FileNotFoundError(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        config.read(config_path, encoding='utf-8')

        # è·å– output_dir
        output_dir = Path(config.get('MAIN', 'output_dir', fallback='outputs'))
        output_dir.mkdir(parents=True, exist_ok=True)

        # è¯»å– FETCHER é…ç½®
        fetcher_timeout = float(config.get('FETCHER', 'timeout', fallback=15))
        fetcher_concurrency = int(config.get('FETCHER', 'concurrency', fallback=5))

        # è¯»å– TESTER é…ç½®
        tester_timeout = float(config.get('TESTER', 'timeout', fallback=5))
        tester_concurrency = int(config.get('TESTER', 'concurrency', fallback=4))
        tester_max_attempts = int(config.get('TESTER', 'max_attempts', fallback=3))
        tester_min_download_speed = float(config.get('TESTER', 'min_download_speed', fallback=0.01))
        tester_enable_logging = config.getboolean('TESTER', 'enable_logging', fallback=False)

        # è¯»å– EXPORTER é…ç½®
        enable_history = config.getboolean('EXPORTER', 'enable_history', fallback=False)

        # è¯»å– BLACKLIST é…ç½®
        blacklist_path = Path(config.get('BLACKLIST', 'blacklist_path', fallback='config/blacklist.txt'))
        if blacklist_path.exists():
            with open(blacklist_path, 'r', encoding='utf-8') as f:
                blacklist = set(line.strip() for line in f if line.strip() and not line.startswith('#'))
        else:
            blacklist = set()

        # è¯»å– PATHS é…ç½®
        urls_path = Path(config.get('PATHS', 'urls_path', fallback='config/urls.txt'))
        templates_path = Path(config.get('PATHS', 'templates_path', fallback='config/templates.txt'))

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not urls_path.exists():
            raise FileNotFoundError(f"âŒ ç¼ºå°‘è®¢é˜…æºæ–‡ä»¶: {urls_path}")
        if not templates_path.exists():
            raise FileNotFoundError(f"âŒ ç¼ºå°‘åˆ†ç±»æ¨¡æ¿æ–‡ä»¶: {templates_path}")

        # é˜¶æ®µ1: è·å–è®¢é˜…æº
        with open(urls_path, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip()]
        
        fetcher = SourceFetcher(
            timeout=fetcher_timeout,
            concurrency=fetcher_concurrency
        )
        progress = StageProgress("ğŸŒ è·å–æºæ•°æ®", len(urls), update_interval=10)
        contents = await fetcher.fetch_all(urls, progress.update)
        progress.complete()

        # é˜¶æ®µ2: è§£æé¢‘é“
        parser = PlaylistParser()
        valid_contents = [c for c in contents if c.strip()]
        progress = StageProgress("ğŸ” è§£æé¢‘é“", len(valid_contents), update_interval=20)
        channels = []
        for content in valid_contents:
            channels.extend(parser.parse(content))
            progress.update()
        progress.complete()

        # é˜¶æ®µ3: æ™ºèƒ½åˆ†ç±»
        matcher = AutoCategoryMatcher(str(templates_path))
        progress = StageProgress("ğŸ·ï¸ åˆ†ç±»é¢‘é“", len(channels), update_interval=50)
        for chan in channels:
            chan.name = matcher.normalize_channel_name(chan.name)
            chan.category = matcher.match(chan.name)
            progress.update()
        progress.complete()

        # è¿‡æ»¤é¢‘é“ï¼šä»…ä¿ç•™æ¨¡æ¿ä¸­å®šä¹‰çš„é¢‘é“
        filtered_channels = [chan for chan in channels if matcher.is_in_template(chan.name)]
        logger.info(f"è¿‡æ»¤åé¢‘é“æ•°é‡: {len(filtered_channels)}/{len(channels)}")

        # è¿‡æ»¤é»‘åå•
        filtered_channels = [chan for chan in filtered_channels if not is_blacklisted(chan, blacklist)]
        logger.info(f"è¿‡æ»¤é»‘åå•åé¢‘é“æ•°é‡: {len(filtered_channels)}")

        # é˜¶æ®µ4: æµ‹é€Ÿæµ‹è¯•
        unique_channels = []
        seen_urls = set()
        for chan in filtered_channels:
            if chan.url not in seen_urls:
                unique_channels.append(chan)
                seen_urls.add(chan.url)
        logger.info(f"å»é‡åé¢‘é“æ•°é‡: {len(unique_channels)}/{len(filtered_channels)}")

        tester = SpeedTester(
            timeout=tester_timeout,
            concurrency=tester_concurrency,
            max_attempts=tester_max_attempts,
            min_download_speed=tester_min_download_speed,
            enable_logging=tester_enable_logging
        )
        progress = StageProgress("â±ï¸ æµ‹é€Ÿæµ‹è¯•", len(unique_channels), update_interval=100)
        failed_urls = set()
        await tester.test_channels(unique_channels, progress.update, failed_urls)
        progress.complete()
        logger.info("æµ‹é€Ÿæµ‹è¯•å®Œæˆ")

        # å†™å…¥å¤±è´¥çš„ URL
        if failed_urls:
            write_failed_urls(failed_urls, config)

        # é˜¶æ®µ5: ç»“æœå¯¼å‡º
        exporter = ResultExporter(
            output_dir=str(output_dir),
            enable_history=enable_history,
            template_path=str(templates_path),
            config=config,
            matcher=matcher  # æ·»åŠ  matcher å‚æ•°
        )
        progress = StageProgress("ğŸ’¾ å¯¼å‡ºç»“æœ", 2, update_interval=1)
        exporter.export(unique_channels, progress.update)
        progress.complete()

        # åˆ†ç±»å¹¶å†™å…¥ IPv4 å’Œ IPv6 åœ°å€
        classify_and_write_ips(unique_channels, config, output_dir, matcher)

        # è¾“å‡ºç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        m3u_filename = config.get('EXPORTER', 'm3u_filename', fallback='all.m3u')
        txt_filename = config.get('EXPORTER', 'txt_filename', fallback='all.txt')
        ipv4_output_path = config.get('PATHS', 'ipv4_output_path', fallback='ipv4.txt')
        ipv6_output_path = config.get('PATHS', 'ipv6_output_path', fallback='ipv6.txt')

        logger.info(f"ğŸ“„ ç”Ÿæˆçš„ M3U æ–‡ä»¶: {(output_dir / m3u_filename).resolve()}")
        logger.info(f"ğŸ“„ ç”Ÿæˆçš„ TXT æ–‡ä»¶: {(output_dir / txt_filename).resolve()}")
        logger.info(f"ğŸ“„ ç”Ÿæˆçš„ IPv4 åœ°å€æ–‡ä»¶: {(output_dir / ipv4_output_path).resolve()}")
        logger.info(f"ğŸ“„ ç”Ÿæˆçš„ IPv6 åœ°å€æ–‡ä»¶: {(output_dir / ipv6_output_path).resolve()}")

        # è¾“å‡ºæ‘˜è¦
        online = sum(1 for c in unique_channels if c.status == 'online')
        logger.info(f"âœ… ä»»åŠ¡å®Œæˆï¼åœ¨çº¿é¢‘é“: {online}/{len(unique_channels)}")
        logger.info(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir.resolve()}")

    except Exception as e:
        logger.error(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        logger.info("ğŸ’¡ æ’æŸ¥å»ºè®®:")
        logger.info("1. æ£€æŸ¥ config ç›®å½•ä¸‹çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        logger.info("2. ç¡®è®¤è®¢é˜…æºURLå¯è®¿é—®")
        logger.info("3. éªŒè¯åˆ†ç±»æ¨¡æ¿æ ¼å¼æ˜¯å¦æ­£ç¡®")

if __name__ == "__main__":
    if os.name == 'nt':
        from asyncio import WindowsSelectorEventLoopPolicy
        asyncio.set_event_loop_policy(WindowsSelectorEventLoopPolicy())
    
    try:
        asyncio.run(main())
    except Exception as e:
        logger.error(f"âŒ å…¨å±€å¼‚å¸¸æ•è·: {str(e)}")
